{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from datasets import ArgoverseV2Dataset\n",
    "from predictors import QCNet\n",
    "from predictors.autoval import AntoQCNet\n",
    "from transforms import TargetBuilder\n",
    "\n",
    "pl.seed_everything(2023, workers=True)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--model\", type=str, default=\"QCNet\")\n",
    "parser.add_argument(\"--root\", type=str, default=\"/home/guanren/Multi-agent-competitive-environment/datasets\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1)\n",
    "parser.add_argument(\"--num_workers\", type=int, default=8)\n",
    "parser.add_argument(\"--pin_memory\", type=bool, default=True)\n",
    "parser.add_argument(\"--persistent_workers\", type=bool, default=True)\n",
    "parser.add_argument(\"--accelerator\", type=str, default=\"auto\")\n",
    "parser.add_argument(\"--devices\", type=int, default=1)\n",
    "parser.add_argument(\"--ckpt_path\", default=\"checkpoints/epoch=10-step=274879.ckpt\", type=str)\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "model = {\n",
    "    \"QCNet\": AntoQCNet,\n",
    "}[args.model].load_from_checkpoint(checkpoint_path=args.ckpt_path)\n",
    "val_dataset = {\n",
    "    \"argoverse_v2\": ArgoverseV2Dataset,\n",
    "}[model.dataset](\n",
    "    root=args.root,\n",
    "    split=\"val\",\n",
    "    transform=TargetBuilder(model.num_historical_steps, model.num_future_steps),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    val_dataset[[val_dataset.raw_file_names.index('0a0ef009-9d44-4399-99e6-50004d345f34')]],\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=args.pin_memory,\n",
    "    persistent_workers=args.persistent_workers,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(accelerator=args.accelerator, devices=args.devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataloader)\n",
    "data = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image as img\n",
    "from typing import Final\n",
    "from random import choices\n",
    "from av2.datasets.motion_forecasting import scenario_serialization\n",
    "from av2.datasets.motion_forecasting.data_schema import (\n",
    "    ArgoverseScenario,\n",
    "    ObjectType,\n",
    "    TrackCategory,\n",
    ")\n",
    "\n",
    "\n",
    "_DRIVABLE_AREA_COLOR: Final[str] = \"#7A7A7A\"\n",
    "_LANE_SEGMENT_COLOR: Final[str] = \"#E0E0E0\"\n",
    "\n",
    "_DEFAULT_ACTOR_COLOR: Final[str] = \"#D3E8EF\"\n",
    "_FOCAL_AGENT_COLOR: Final[str] = \"#ECA25B\"\n",
    "_AV_COLOR: Final[str] = \"#007672\"\n",
    "_BOUNDING_BOX_ZORDER: Final[\n",
    "    int\n",
    "] = 100  # Ensure actor bounding boxes are plotted on top of all map elements\n",
    "\n",
    "_STATIC_OBJECT_TYPES = {\n",
    "    ObjectType.STATIC,\n",
    "    ObjectType.BACKGROUND,\n",
    "    ObjectType.CONSTRUCTION,\n",
    "    ObjectType.RIDERLESS_BICYCLE,\n",
    "}\n",
    "_ESTIMATED_VEHICLE_LENGTH_M: Final[float] = 4.0\n",
    "_ESTIMATED_VEHICLE_WIDTH_M: Final[float] = 2.0\n",
    "_ESTIMATED_CYCLIST_LENGTH_M: Final[float] = 2.0\n",
    "_ESTIMATED_CYCLIST_WIDTH_M: Final[float] = 0.7\n",
    "\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from av2.map.map_api import ArgoverseStaticMap\n",
    "from av2.datasets.motion_forecasting.data_schema import (\n",
    "    ArgoverseScenario,\n",
    "    ObjectType,\n",
    "    TrackCategory,\n",
    ")\n",
    "\n",
    "\n",
    "def _plot_static_map_elements(\n",
    "    static_map: ArgoverseStaticMap, show_ped_xings: bool = False\n",
    ") -> None:\n",
    "    \"\"\"Plot all static map elements associated with an Argoverse scenario.\n",
    "\n",
    "    Args:\n",
    "        static_map: Static map containing elements to be plotted.\n",
    "        show_ped_xings: Configures whether pedestrian crossings should be plotted.\n",
    "    \"\"\"\n",
    "    # Plot drivable areas\n",
    "    for drivable_area in static_map.vector_drivable_areas.values():\n",
    "        _plot_polygons([drivable_area.xyz], alpha=0.5, color=_DRIVABLE_AREA_COLOR)\n",
    "\n",
    "    # Plot lane segments\n",
    "    for lane_segment in static_map.vector_lane_segments.values():\n",
    "        _plot_polylines(\n",
    "            [\n",
    "                lane_segment.left_lane_boundary.xyz,\n",
    "                lane_segment.right_lane_boundary.xyz,\n",
    "            ],\n",
    "            line_width=0.5,\n",
    "            color=_LANE_SEGMENT_COLOR,\n",
    "        )\n",
    "\n",
    "    # Plot pedestrian crossings\n",
    "    if show_ped_xings:\n",
    "        for ped_xing in static_map.vector_pedestrian_crossings.values():\n",
    "            _plot_polylines(\n",
    "                [ped_xing.edge1.xyz, ped_xing.edge2.xyz],\n",
    "                alpha=1.0,\n",
    "                color=_LANE_SEGMENT_COLOR,\n",
    "            )\n",
    "\n",
    "\n",
    "def _plot_actor_tracks(ax: plt.Axes, scenario, timestep: int):\n",
    "    \"\"\"Plot all actor tracks (up to a particular time step) associated with an Argoverse scenario.\n",
    "\n",
    "    Args:\n",
    "        ax: Axes on which actor tracks should be plotted.\n",
    "        scenario: Argoverse scenario for which to plot actor tracks.\n",
    "        timestep: Tracks are plotted for all actor data up to the specified time step.\n",
    "\n",
    "    Returns:\n",
    "        track_bounds: (x_min, x_max, y_min, y_max) bounds for the extent of actor tracks.\n",
    "    \"\"\"\n",
    "    track_bounds = None\n",
    "    for track in scenario.tracks:\n",
    "        # Get timesteps for which actor data is valid\n",
    "        actor_timesteps = np.array(\n",
    "            [\n",
    "                object_state.timestep\n",
    "                for object_state in track.object_states\n",
    "                if object_state.timestep <= timestep\n",
    "            ]\n",
    "        )\n",
    "        if actor_timesteps.shape[0] < 1 or actor_timesteps[-1] != timestep:\n",
    "            continue\n",
    "\n",
    "        # Get actor trajectory and heading history\n",
    "        actor_trajectory = np.array(\n",
    "            [\n",
    "                list(object_state.position)\n",
    "                for object_state in track.object_states\n",
    "                if object_state.timestep <= timestep\n",
    "            ]\n",
    "        )\n",
    "        actor_headings: NDArrayFloat = np.array(\n",
    "            [\n",
    "                object_state.heading\n",
    "                for object_state in track.object_states\n",
    "                if object_state.timestep <= timestep\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Plot polyline for focal agent location history\n",
    "        track_color = _DEFAULT_ACTOR_COLOR\n",
    "        if track.category == TrackCategory.FOCAL_TRACK:\n",
    "            x_min, x_max = actor_trajectory[:, 0].min(), actor_trajectory[:, 0].max()\n",
    "            y_min, y_max = actor_trajectory[:, 1].min(), actor_trajectory[:, 1].max()\n",
    "            track_bounds = (x_min, x_max, y_min, y_max)\n",
    "            track_color = _FOCAL_AGENT_COLOR\n",
    "            _plot_polylines(\n",
    "                [\n",
    "                    np.array(\n",
    "                        [\n",
    "                            list(object_state.position)\n",
    "                            for object_state in track.object_states\n",
    "                            if object_state.timestep > timestep\n",
    "                        ]\n",
    "                    )\n",
    "                ],\n",
    "                color=\"black\",\n",
    "                line_width=2,\n",
    "                style=\"--\",\n",
    "            )\n",
    "            _plot_polylines([actor_trajectory], color=track_color, line_width=2)\n",
    "        elif track.track_id == \"AV\":\n",
    "            track_color = _AV_COLOR\n",
    "        elif track.object_type in _STATIC_OBJECT_TYPES:\n",
    "            continue\n",
    "\n",
    "        # Plot bounding boxes for all vehicles and cyclists\n",
    "        if track.object_type == ObjectType.VEHICLE:\n",
    "            _plot_actor_bounding_box(\n",
    "                ax,\n",
    "                actor_trajectory[-1],\n",
    "                actor_headings[-1],\n",
    "                track_color,\n",
    "                (_ESTIMATED_VEHICLE_LENGTH_M, _ESTIMATED_VEHICLE_WIDTH_M),\n",
    "            )\n",
    "        elif (\n",
    "            track.object_type == ObjectType.CYCLIST\n",
    "            or track.object_type == ObjectType.MOTORCYCLIST\n",
    "        ):\n",
    "            _plot_actor_bounding_box(\n",
    "                ax,\n",
    "                actor_trajectory[-1],\n",
    "                actor_headings[-1],\n",
    "                track_color,\n",
    "                (_ESTIMATED_CYCLIST_LENGTH_M, _ESTIMATED_CYCLIST_WIDTH_M),\n",
    "            )\n",
    "        else:\n",
    "            plt.plot(\n",
    "                actor_trajectory[-1, 0],\n",
    "                actor_trajectory[-1, 1],\n",
    "                \"o\",\n",
    "                color=track_color,\n",
    "                markersize=4,\n",
    "            )\n",
    "\n",
    "    return track_bounds\n",
    "\n",
    "\n",
    "def _plot_polylines(\n",
    "    polylines,\n",
    "    *,\n",
    "    style: str = \"-\",\n",
    "    line_width: float = 1.0,\n",
    "    alpha: float = 1.0,\n",
    "    color: str = \"r\",\n",
    ") -> None:\n",
    "    \"\"\"Plot a group of polylines with the specified config.\n",
    "\n",
    "    Args:\n",
    "        polylines: Collection of (N, 2) polylines to plot.\n",
    "        style: Style of the line to plot (e.g. `-` for solid, `--` for dashed)\n",
    "        line_width: Desired width for the plotted lines.\n",
    "        alpha: Desired alpha for the plotted lines.\n",
    "        color: Desired color for the plotted lines.\n",
    "    \"\"\"\n",
    "    for polyline in polylines:\n",
    "        plt.plot(\n",
    "            polyline[:, 0],\n",
    "            polyline[:, 1],\n",
    "            style,\n",
    "            linewidth=line_width,\n",
    "            color=color,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "\n",
    "def _plot_polygons(polygons, *, alpha: float = 1.0, color: str = \"r\") -> None:\n",
    "    \"\"\"Plot a group of filled polygons with the specified config.\n",
    "\n",
    "    Args:\n",
    "        polygons: Collection of polygons specified by (N,2) arrays of vertices.\n",
    "        alpha: Desired alpha for the polygon fill.\n",
    "        color: Desired color for the polygon.\n",
    "    \"\"\"\n",
    "    for polygon in polygons:\n",
    "        plt.fill(polygon[:, 0], polygon[:, 1], color=color, alpha=alpha)\n",
    "\n",
    "\n",
    "def _plot_actor_bounding_box(\n",
    "    ax: plt.Axes, cur_location, heading: float, color: str, bbox_size\n",
    ") -> None:\n",
    "    \"\"\"Plot an actor bounding box centered on the actor's current location.\n",
    "\n",
    "    Args:\n",
    "        ax: Axes on which actor bounding box should be plotted.\n",
    "        cur_location: Current location of the actor (2,).\n",
    "        heading: Current heading of the actor (in radians).\n",
    "        color: Desired color for the bounding box.\n",
    "        bbox_size: Desired size for the bounding box (length, width).\n",
    "    \"\"\"\n",
    "    (bbox_length, bbox_width) = bbox_size\n",
    "\n",
    "    # Compute coordinate for pivot point of bounding box\n",
    "    d = np.hypot(bbox_length, bbox_width)\n",
    "    theta_2 = math.atan2(bbox_width, bbox_length)\n",
    "    pivot_x = cur_location[0] - (d / 2) * math.cos(heading + theta_2)\n",
    "    pivot_y = cur_location[1] - (d / 2) * math.sin(heading + theta_2)\n",
    "\n",
    "    vehicle_bounding_box = Rectangle(\n",
    "        (pivot_x, pivot_y),\n",
    "        bbox_length,\n",
    "        bbox_width,\n",
    "        np.degrees(heading),\n",
    "        color=color,\n",
    "        zorder=_BOUNDING_BOX_ZORDER,\n",
    "    )\n",
    "    ax.add_patch(vehicle_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_id = data[\"scenario_id\"][0]\n",
    "argoverse_scenario_dir = Path(\"/home/guanren/Multi-agent-competitive-environment/datasets/val/raw\")\n",
    "\n",
    "all_scenario_files = sorted(argoverse_scenario_dir.rglob(f\"*_{scenario_id}.parquet\"))\n",
    "scenario_file_list = list(all_scenario_files)\n",
    "scenario_path = scenario_file_list[0]\n",
    "print(scenario_path)\n",
    "\n",
    "static_map_path = scenario_path.parents[0] / f\"log_map_archive_{scenario_id}.json\"\n",
    "\n",
    "scenario = scenario_serialization.load_argoverse_scenario_parquet(scenario_path)\n",
    "scenario_static_map = ArgoverseStaticMap.from_json(static_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(bounds=80.0):\n",
    "    plot_bounds = (0, 0, 0, 0)\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    _plot_static_map_elements(scenario_static_map)\n",
    "    cur_plot_bounds = _plot_actor_tracks(ax, scenario, 50)\n",
    "    if cur_plot_bounds:\n",
    "        plot_bounds = cur_plot_bounds\n",
    "    plt.xlim(\n",
    "        plot_bounds[0] - bounds,\n",
    "        plot_bounds[1] + bounds,\n",
    "    )\n",
    "    plt.ylim(\n",
    "        plot_bounds[2] - bounds,\n",
    "        plot_bounds[3] + bounds,\n",
    "    )\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    plt.margins(0, 0)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "plot_traj()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "for param in model.decoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from utils import wrap_angle\n",
    "import torch\n",
    "import copy\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "if isinstance(data, Batch):\n",
    "    data['agent']['av_index'] += data['agent']['ptr'][:-1]\n",
    "\n",
    "def get_transform_mat(input_data):\n",
    "    origin = input_data[\"agent\"][\"position\"][:, model.num_historical_steps - 1]\n",
    "    theta = input_data[\"agent\"][\"heading\"][:, model.num_historical_steps - 1]\n",
    "    cos, sin = theta.cos(), theta.sin()\n",
    "    rot_mat = theta.new_zeros(input_data[\"agent\"][\"num_nodes\"], 2, 2)\n",
    "    rot_mat[:, 0, 0] = cos\n",
    "    rot_mat[:, 0, 1] = -sin\n",
    "    rot_mat[:, 1, 0] = sin\n",
    "    rot_mat[:, 1, 1] = cos\n",
    "    return origin,theta,rot_mat\n",
    "init_origin,init_theta,init_rot_mat=get_transform_mat(data)\n",
    "def get_auto_pred(input_data, loc_refine_pos, loc_refine_head, offset, anchor=None):\n",
    "    old_anchor=origin,theta,rot_mat=get_transform_mat(input_data)\n",
    "    # auto_index = data['agent']['valid_mask'][:,model.num_historical_steps]\n",
    "    input_data[\"agent\"][\"valid_mask\"] = (\n",
    "        torch.cat(\n",
    "            (\n",
    "                input_data[\"agent\"][\"valid_mask\"][..., offset:],\n",
    "                torch.zeros(input_data[\"agent\"][\"valid_mask\"].shape[:-1] + (5,)).cuda(),\n",
    "            ),\n",
    "            dim=-1,\n",
    "        )\n",
    "    ).bool()\n",
    "    input_data[\"agent\"][\"valid_mask\"][:, 0] = False\n",
    "    new_position = torch.matmul(\n",
    "        loc_refine_pos[..., :2], rot_mat.swapaxes(-1, -2)\n",
    "    ) + origin[:, :2].unsqueeze(1)\n",
    "    input_position = torch.zeros_like(input_data[\"agent\"][\"position\"])\n",
    "    input_position[:, :-offset] = input_data[\"agent\"][\"position\"][:, offset:]\n",
    "    input_position[\n",
    "        :, model.num_historical_steps - offset : model.num_historical_steps, :2\n",
    "    ] = new_position[:, :offset]\n",
    "\n",
    "    input_v = torch.zeros_like(input_data[\"agent\"][\"velocity\"])\n",
    "    input_v[:, :-offset] = input_data[\"agent\"][\"velocity\"][:, offset:]\n",
    "    input_v[:, model.num_historical_steps - offset : model.num_historical_steps, :2] = (\n",
    "        new_position[:, 1:] - new_position[:, :-1]\n",
    "    )[:, :offset] / 0.1\n",
    "    \n",
    "    \n",
    "\n",
    "    input_heading = torch.zeros_like(input_data[\"agent\"][\"heading\"])\n",
    "    input_heading[:, :-offset] = input_data[\"agent\"][\"heading\"][:, offset:]\n",
    "    input_heading[\n",
    "        :, model.num_historical_steps - offset : model.num_historical_steps\n",
    "    ] = wrap_angle(loc_refine_head+theta.unsqueeze(-1))[:,:offset]\n",
    "    input_data[\"agent\"][\"position\"] = input_position\n",
    "    input_data[\"agent\"][\"heading\"] = input_heading\n",
    "    input_data[\"agent\"][\"velocity\"] = input_v\n",
    "\n",
    "    auto_pred = model(input_data)\n",
    "    new_anchor=get_transform_mat(input_data)\n",
    "    def get_transform_res(old_anchor,new_anchor,auto_pred):\n",
    "        old_origin,old_theta,old_rot_mat=old_anchor\n",
    "        new_origin,new_theta,new_rot_mat=new_anchor\n",
    "        new_trans_position_propose = torch.einsum(\n",
    "            \"bijk,bkn->bijn\",\n",
    "            auto_pred[\"loc_propose_pos\"][..., : model.output_dim],\n",
    "            new_rot_mat.swapaxes(-1, -2),\n",
    "        ) + new_origin[:, :2].unsqueeze(1).unsqueeze(1)\n",
    "        new_pred=copy.deepcopy(auto_pred)\n",
    "        new_pred[\"loc_propose_pos\"][..., : model.output_dim] = torch.einsum(\n",
    "            \"bijk,bkn->bijn\",\n",
    "            new_trans_position_propose.cuda() - old_origin[:, :2].unsqueeze(1).unsqueeze(1).cuda(),\n",
    "            old_rot_mat.cuda(),\n",
    "        )\n",
    "        new_pred[\"scale_propose_pos\"][..., model.output_dim - 1] = wrap_angle(\n",
    "            auto_pred[\"scale_propose_pos\"][..., model.output_dim - 1].cuda()\n",
    "            + new_theta.unsqueeze(-1).unsqueeze(-1).cuda()\n",
    "            - old_theta.unsqueeze(-1).unsqueeze(-1).cuda()\n",
    "        )\n",
    "\n",
    "        new_trans_position_refine = torch.einsum(\n",
    "            \"bijk,bkn->bijn\",\n",
    "            auto_pred[\"loc_refine_pos\"][..., : model.output_dim].cuda(),\n",
    "            new_rot_mat.swapaxes(-1, -2).cuda(),\n",
    "        ) + new_origin[:, :2].unsqueeze(1).unsqueeze(1).cuda()\n",
    "        new_pred[\"loc_refine_pos\"][..., : model.output_dim] = torch.einsum(\n",
    "            \"bijk,bkn->bijn\",\n",
    "            new_trans_position_refine.cuda() - old_origin[:, :2].unsqueeze(1).unsqueeze(1).cuda(),\n",
    "            old_rot_mat.cuda(),\n",
    "        )\n",
    "        new_pred[\"scale_refine_pos\"][..., model.output_dim - 1] = wrap_angle(\n",
    "            auto_pred[\"scale_refine_pos\"][..., model.output_dim - 1].cuda()\n",
    "            + new_theta.unsqueeze(-1).unsqueeze(-1).cuda()\n",
    "            - old_theta.unsqueeze(-1).unsqueeze(-1).cuda()\n",
    "        )\n",
    "        return new_pred,(new_trans_position_propose, new_trans_position_refine),\n",
    "\n",
    "    _,(new_trans_position_propose, new_trans_position_refine)=get_transform_res(old_anchor,new_anchor,auto_pred)\n",
    "    if model.output_head:\n",
    "        auto_traj_propose = torch.cat(\n",
    "            [\n",
    "                auto_pred[\"loc_propose_pos\"][..., : model.output_dim],\n",
    "                auto_pred[\"loc_propose_head\"],\n",
    "                auto_pred[\"scale_propose_pos\"][..., : model.output_dim],\n",
    "                auto_pred[\"conc_propose_head\"],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        auto_traj_refine = torch.cat(\n",
    "            [\n",
    "                auto_pred[\"loc_refine_pos\"][..., : model.output_dim],\n",
    "                auto_pred[\"loc_refine_head\"],\n",
    "                auto_pred[\"scale_refine_pos\"][..., : model.output_dim],\n",
    "                auto_pred[\"conc_refine_head\"],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "    else:\n",
    "        auto_traj_propose = torch.cat([auto_pred['loc_propose_pos'][..., :model.output_dim],\n",
    "                                auto_pred['scale_propose_pos'][..., :model.output_dim]], dim=-1)\n",
    "        auto_traj_refine = torch.cat([auto_pred['loc_refine_pos'][..., :model.output_dim],\n",
    "                                auto_pred['scale_refine_pos'][..., :model.output_dim]], dim=-1)\n",
    "    if anchor is not None:\n",
    "        anchor_auto_pred,_=get_transform_res(anchor,new_anchor,auto_pred)\n",
    "        if model.output_head:\n",
    "            anchor_auto_traj_propose = torch.cat([anchor_auto_pred['loc_propose_pos'][..., :model.output_dim],\n",
    "                                                  anchor_auto_pred[\"loc_propose_head\"],\n",
    "                                    anchor_auto_pred['scale_propose_pos'][..., :model.output_dim],\n",
    "                                    anchor_auto_pred[\"conc_propose_head\"],], dim=-1)\n",
    "            anchor_auto_traj_refine = torch.cat([anchor_auto_pred['loc_refine_pos'][..., :model.output_dim],\n",
    "                                                 anchor_auto_pred[\"loc_refine_head\"],\n",
    "                                    anchor_auto_pred['scale_refine_pos'][..., :model.output_dim],\n",
    "                                    anchor_auto_pred[\"conc_refine_head\"],], dim=-1)\n",
    "        else:\n",
    "            anchor_auto_traj_propose = torch.cat([anchor_auto_pred['loc_propose_pos'][..., :model.output_dim],\n",
    "                                    anchor_auto_pred['scale_propose_pos'][..., :model.output_dim]], dim=-1)\n",
    "            anchor_auto_traj_refine = torch.cat([anchor_auto_pred['loc_refine_pos'][..., :model.output_dim],\n",
    "                                    anchor_auto_pred['scale_refine_pos'][..., :model.output_dim]], dim=-1)\n",
    "\n",
    "    return (\n",
    "        input_data,\n",
    "        auto_pred,\n",
    "        auto_traj_refine,\n",
    "        auto_traj_propose,\n",
    "        (new_trans_position_propose, new_trans_position_refine),\n",
    "        None if anchor is None else (anchor_auto_traj_propose, anchor_auto_traj_refine)\n",
    "    )\n",
    "\n",
    "def reward_function(new_data,agent_index,timestep):\n",
    "                \n",
    "        reward1 = reward2 = reward3 = 0\n",
    "        ground_truth = data['agent']['position'][agent_index, model.num_historical_steps + model.num_future_steps -1:model.num_historical_steps + model.num_future_steps, :model.output_dim]\n",
    "        pre_distance = torch.norm(new_data['agent']['position'][agent_index, model.num_historical_steps-2:model.num_historical_steps-1, :model.output_dim]-ground_truth,dim=-1)\n",
    "        next_distance = torch.norm(new_data['agent']['position'][agent_index, model.num_historical_steps-1:model.num_historical_steps, :model.output_dim]-ground_truth,dim=-1)\n",
    "\n",
    "        if new_data['agent']['valid_mask'][agent_index, model.num_historical_steps-1:model.num_historical_steps]:\n",
    "            if next_distance > pre_distance:\n",
    "                reward1 = 100\n",
    "            elif timestep <= model.num_future_steps-1 and next_distance < 1:\n",
    "                reward1 = 50\n",
    "            elif timestep < model.num_future_steps-1 and next_distance < pre_distance:\n",
    "                reward1 = (50/model.num_future_steps)*(timestep+1)\n",
    "            elif timestep == model.num_future_steps-1 and next_distance < pre_distance:\n",
    "                reward1 = -50\n",
    "        else:\n",
    "            return reward1+reward2+reward3\n",
    "\n",
    "        for i in range(data['agent']['num_nodes']):\n",
    "            if i==agent_index:\n",
    "                continue\n",
    "            distance = torch.norm(new_data['agent']['position'][agent_index, model.num_historical_steps-1:model.num_historical_steps, :model.output_dim]-new_data['agent']['position'][i, model.num_historical_steps-1:model.num_historical_steps, :model.output_dim],dim=-1)\n",
    "            if distance < 1e-1:\n",
    "                 break\n",
    "        if distance < 1e-1:\n",
    "            reward2 = -100\n",
    "        left_bound = []\n",
    "        right_bound = []\n",
    "        for i in range(len(data['map_point']['side'])):\n",
    "            if data['map_point']['side'][i] == 0:\n",
    "                left_bound.append(tuple(data['map_point']['position'][i,:2]))\n",
    "            if data['map_point']['side'][i] == 1:\n",
    "                right_bound.append(tuple(data['map_point']['position'][i,:2]))\n",
    "        left_polygon = LineString(left_bound)\n",
    "        right_polygon = LineString(right_bound)\n",
    "        car_point = Point(tuple(new_data['agent']['position'][agent_index, model.num_historical_steps-1:model.num_historical_steps, :model.output_dim].flatten().cpu().numpy()))\n",
    "        nearest_left = nearest_points(left_polygon, car_point)[0]\n",
    "        nearest_right = nearest_points(right_polygon, car_point)[0]\n",
    "        distance_to_nearest_left = car_point.distance(nearest_left)\n",
    "        distance_to_nearest_right = car_point.distance(nearest_right)\n",
    "        lane_width = nearest_left.distance(nearest_right)\n",
    "        if distance_to_nearest_left + distance_to_nearest_right > lane_width:\n",
    "            reward3 = -50\n",
    "\n",
    "        # total_reward = np.array([reward1, reward2, reward3])\n",
    "        # mean_reward = np.mean(total_reward)\n",
    "        # std_reward = np.std(total_reward)    \n",
    "        # normalized_reward = (total_reward - mean_reward) / std_reward\n",
    "        # return float(np.sum(normalized_reward))\n",
    "        return reward1+reward2+reward3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_actor_tracks_with_data(ax: plt.Axes, data, timestep: int):\n",
    "    \"\"\"Plot all actor tracks (up to a particular time step) associated with an Argoverse scenario.\n",
    "\n",
    "    Args:\n",
    "        ax: Axes on which actor tracks should be plotted.\n",
    "        scenario: Argoverse scenario for which to plot actor tracks.\n",
    "        timestep: Tracks are plotted for all actor data up to the specified time step.\n",
    "\n",
    "    Returns:\n",
    "        track_bounds: (x_min, x_max, y_min, y_max) bounds for the extent of actor tracks.\n",
    "    \"\"\"\n",
    "    track_bounds = None\n",
    "    for i in range(data['agent']['num_nodes']):\n",
    "        if not (data['agent']['valid_mask'][i,timestep]):\n",
    "            continue\n",
    "        # Get timesteps for which actor data is valid\n",
    "        track_color = _DEFAULT_ACTOR_COLOR\n",
    "        \n",
    "        # Get actor trajectory and heading history\n",
    "\n",
    "        actor_trajectory = data['agent']['position'][i,:timestep+1][data['agent']['valid_mask'][i,:timestep+1]].cpu()\n",
    "        actor_headings = data['agent']['heading'][i,:timestep+1][data['agent']['valid_mask'][i,:timestep+1]].cpu()\n",
    "\n",
    "\n",
    "        if data['agent']['category'][i] == TrackCategory.FOCAL_TRACK.value:\n",
    "            x_min, x_max = actor_trajectory[:, 0].min(), actor_trajectory[:, 0].max()\n",
    "            y_min, y_max = actor_trajectory[:, 1].min(), actor_trajectory[:, 1].max()\n",
    "            track_bounds = (x_min, x_max, y_min, y_max)\n",
    "            track_color = _FOCAL_AGENT_COLOR\n",
    "            _plot_polylines([actor_trajectory], color=track_color, line_width=2)\n",
    "            ax.arrow(actor_trajectory[-1,0], actor_trajectory[-1,1], data['agent']['velocity'][i,timestep,0].cpu(),data['agent']['velocity'][i,timestep,1].cpu(),\n",
    "              width=0.1,\n",
    "              length_includes_head=True,\n",
    "              head_width=0.75,\n",
    "              head_length=1,\n",
    "              fc='r',\n",
    "              ec='b')\n",
    "        elif i==data['agent']['av_index']:\n",
    "            track_color = _AV_COLOR\n",
    "        elif i==data['agent']['num_nodes']-1:\n",
    "            _plot_polylines([actor_trajectory], color=\"black\", line_width=2)\n",
    "            track_color = \"black\"\n",
    "            ax.arrow(actor_trajectory[-1,0], actor_trajectory[-1,1], data['agent']['velocity'][i,timestep,0].cpu(),data['agent']['velocity'][i,timestep,1].cpu(),\n",
    "              width=0.1,\n",
    "              length_includes_head=True,\n",
    "              head_width=0.75,\n",
    "              head_length=1,\n",
    "              fc='r',\n",
    "              ec='y')\n",
    "        elif data['agent']['type'][i]>4:\n",
    "            continue\n",
    "\n",
    "        # Plot bounding boxes for all vehicles and cyclists\n",
    "        if data['agent']['type'][i]==0:\n",
    "            _plot_actor_bounding_box(\n",
    "                ax,\n",
    "                actor_trajectory[-1],\n",
    "                actor_headings[-1],\n",
    "                track_color,\n",
    "                (_ESTIMATED_VEHICLE_LENGTH_M, _ESTIMATED_VEHICLE_WIDTH_M),\n",
    "            )\n",
    "        elif (\n",
    "            data['agent']['type'][i]==2\n",
    "            or data['agent']['type'][i]==3\n",
    "        ):\n",
    "            _plot_actor_bounding_box(\n",
    "                ax,\n",
    "                actor_trajectory[-1],\n",
    "                actor_headings[-1],\n",
    "                track_color,\n",
    "                (_ESTIMATED_CYCLIST_LENGTH_M, _ESTIMATED_CYCLIST_WIDTH_M),\n",
    "            )\n",
    "        else:\n",
    "            plt.plot(\n",
    "                actor_trajectory[-1, 0],\n",
    "                actor_trajectory[-1, 1],\n",
    "                \"o\",\n",
    "                color=track_color,\n",
    "                markersize=4,\n",
    "            )\n",
    "\n",
    "    return track_bounds\n",
    "\n",
    "\n",
    "\n",
    "def plot_traj_with_data(data,t=50,bounds=80.0):\n",
    "    plot_bounds = (0, 0, 0, 0)\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    _plot_static_map_elements(scenario_static_map)\n",
    "    cur_plot_bounds = _plot_actor_tracks_with_data(ax, data, t)\n",
    "    if cur_plot_bounds:\n",
    "        plot_bounds = cur_plot_bounds\n",
    "    plt.xlim(\n",
    "        plot_bounds[0] - bounds,\n",
    "        plot_bounds[1] + bounds,\n",
    "    )\n",
    "    plt.ylim(\n",
    "        plot_bounds[2] - bounds,\n",
    "        plot_bounds[3] + bounds,\n",
    "    )\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    plt.margins(0, 0)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "\n",
    "plot_traj_with_data(data,t=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration = 1.5\n",
    "arr_s_x = np.array([])\n",
    "arr_s_y = np.array([])\n",
    "arr_v_x = np.array([])\n",
    "arr_v_y = np.array([])\n",
    "v0_x = 5*math.cos(data['agent']['heading'][data['agent']['category']==3][0,50])\n",
    "v0_y = 5\n",
    "t = 0.1\n",
    "x0 = x = 5258.5\n",
    "y0 = y = 320.6\n",
    "v_x = 0\n",
    "v_y = 0\n",
    "new_heading=torch.empty_like(data['agent']['heading'][0])\n",
    "new_heading[:]=1.9338\n",
    "\n",
    "for i in range(80):\n",
    "    a_x = acceleration*math.cos(new_heading[i+30])\n",
    "    x = x + v0_x*t + 0.5*acceleration*(t**2)\n",
    "    v0_x = v0_x + a_x*t\n",
    "    v_x = v0_x\n",
    "    arr_s_x = np.append(arr_s_x,x)\n",
    "    arr_v_x = np.append(arr_v_x,v_x)\n",
    "\n",
    "    a_y = math.sqrt(acceleration**2-a_x**2)\n",
    "    y = y + v0_y*t + 0.5*acceleration*(t**2)\n",
    "    v0_y = v0_y + a_y*t\n",
    "    v_y = v0_y\n",
    "    arr_s_y = np.append(arr_s_y,y)\n",
    "    arr_v_y = np.append(arr_v_y,v_y)\n",
    "\n",
    "new_position=torch.empty_like(data['agent']['position'][0])\n",
    "new_position[:,0]=torch.tensor(np.concatenate([np.ones(30)*x0,arr_s_x]))\n",
    "new_position[:,1]=torch.tensor(np.concatenate([np.ones(30)*y0,arr_s_y]))\n",
    "\n",
    "new_velocity=torch.empty_like(data['agent']['velocity'][0])\n",
    "new_velocity[:,0]=torch.tensor(np.concatenate([np.ones(30)*0,arr_v_x]))\n",
    "new_velocity[:,1]=torch.tensor(np.concatenate([np.ones(30)*0,arr_v_y]))\n",
    "\n",
    "def add_new_agent(data,new_position,new_heading,new_velocity):\n",
    "    data=data.clone()\n",
    "    data['agent']['num_nodes']+=1   #num_nodes\n",
    "    #av_index\n",
    "    data['agent']['valid_mask']=torch.cat([data['agent']['valid_mask'],torch.ones_like(data['agent']['valid_mask'][[0]])]) #valid_mask\n",
    "    data['agent']['predict_mask']=torch.cat([data['agent']['predict_mask'],torch.ones_like(data['agent']['predict_mask'][[0]])]) #predict_mask\n",
    "    data['agent']['id'][0].append(str(max(map(int,filter(str.isdigit,data['agent']['id'][0])))+1)) #id\n",
    "    data['agent']['type']=torch.cat([data['agent']['type'],torch.tensor([0])]) #type\n",
    "    data['agent']['category']=torch.cat([data['agent']['category'],torch.tensor([2])]) #category\n",
    "    data['agent']['position']=torch.cat([data['agent']['position'],new_position[None,:]]) #position\n",
    "    data['agent']['heading']=torch.cat([data['agent']['heading'],new_heading[None,:]]) #heading\n",
    "    data['agent']['velocity']=torch.cat([data['agent']['velocity'],new_velocity[None,:]]) #velocity\n",
    "    #target\n",
    "    data['agent']['batch']=torch.cat([data['agent']['batch'],torch.tensor([0])]) #batch\n",
    "    data['agent']['ptr'][1]+=1    #ptr\n",
    "    return data\n",
    "new_input_data=add_new_agent(data,new_position,new_heading,new_velocity)\n",
    "plot_traj_with_data(new_input_data,bounds=30,t=40)\n",
    "# new_input_data['agent']['valid_mask'][:]=False\n",
    "# new_input_data['agent']['valid_mask'][new_input_data[\"agent\"][\"category\"] == 3] = True\n",
    "# new_input_data['agent']['valid_mask'][new_input_data[\"agent\"][\"category\"] == 2] = True\n",
    "# new_input_data['agent']['valid_mask'][2] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "with torch.no_grad():\n",
    "    offset=5\n",
    "    new_data=new_input_data.cuda().clone()\n",
    "    pred = model(new_data)\n",
    "    traj_propose = torch.cat([pred['loc_propose_pos'][..., :model.output_dim],\n",
    "                            pred['scale_propose_pos'][..., :model.output_dim]], dim=-1)\n",
    "    traj_refine = torch.cat([pred['loc_refine_pos'][..., :model.output_dim],\n",
    "                            pred['scale_refine_pos'][..., :model.output_dim]], dim=-1)\n",
    "    origin,theta,rot_mat=get_transform_mat(new_data)\n",
    "    new_true_trans_position_refine = torch.einsum(\n",
    "        \"bijk,bkn->bijn\",\n",
    "        pred[\"loc_refine_pos\"][..., : model.output_dim],\n",
    "        rot_mat.swapaxes(-1, -2),\n",
    "    ) + origin[:, :2].unsqueeze(1).unsqueeze(1)\n",
    "    auto_pred=pred\n",
    "    init_origin,init_theta,init_rot_mat=get_transform_mat(new_data)\n",
    "\n",
    "    for i in range(30,110):\n",
    "        if i<50:\n",
    "            plot_traj_with_data(new_data,bounds=30,t=i)\n",
    "        else:\n",
    "            if i%offset==0:\n",
    "                # true_trans_position_propose=new_true_trans_position_propose\n",
    "                true_trans_position_refine=new_true_trans_position_refine\n",
    "                # reg_mask = new_data['agent']['predict_mask'][:, model.num_historical_steps:]\n",
    "                # cls_mask = new_data['agent']['predict_mask'][:, -1]\n",
    "                # gt = torch.cat([data['agent']['target'][...,timestep:timestep+offset, :model.output_dim], data['agent']['target'][...,timestep:timestep+offset, -1:]], dim=-1)\n",
    "                # l2_norm = (torch.norm(traj_propose[:-1,...,:offset, :model.output_dim] -\n",
    "                #                     gt[..., :model.output_dim].unsqueeze(1), p=2, dim=-1) * reg_mask[:-1,...,:offset].unsqueeze(1)).sum(dim=-1)\n",
    "                # best_mode = l2_norm.argmin(dim=-1)\n",
    "                best_mode=torch.randint(1,size=(new_input_data['agent']['num_nodes'],))\n",
    "                new_data, auto_pred, _, _, (new_true_trans_position_propose, new_true_trans_position_refine),(traj_propose, traj_refine) = get_auto_pred(\n",
    "                    new_data, auto_pred[\"loc_refine_pos\"][torch.arange(traj_propose.size(0)),best_mode], auto_pred[\"loc_refine_head\"][torch.arange(traj_propose.size(0)),best_mode,:,0], offset,anchor=(init_origin,init_theta,init_rot_mat)\n",
    "                )\n",
    "                plot_traj_with_data(new_data,bounds=30,t=50-offset)\n",
    "            else:\n",
    "                plot_traj_with_data(new_data,bounds=30,t=50-offset+i%offset)\n",
    "            for j in range(6):\n",
    "                xy = true_trans_position_refine[new_data[\"agent\"][\"category\"] == 3][0].cpu()\n",
    "                plt.plot(xy[j, ..., 0], xy[j, ..., 1])\n",
    "\n",
    "        plt.title(f\"timestep={i}\")\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        frame = img.open(buf)\n",
    "        frames.append(frame)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "vid_path = \"test.mp4\"\n",
    "video = cv2.VideoWriter(vid_path, fourcc, fps=10, frameSize=frames[0].size)\n",
    "for i in range(len(frames)):\n",
    "    frame_temp = frames[i].copy()\n",
    "    video.write(cv2.cvtColor(np.array(frame_temp), cv2.COLOR_RGB2BGR))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PPO.mappo import PPO\n",
    "import yaml\n",
    "\n",
    "episodes = 50\n",
    "cumulative_reward = [{'return': []} for _ in range(new_input_data['agent']['num_nodes'])]\n",
    "\n",
    "with open(\"configs/PPO.yaml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "file.close()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for episode in range(episodes):\n",
    "        offset=5\n",
    "        new_data=new_input_data.cuda().clone()\n",
    "        pred = model(new_data)\n",
    "        traj_propose = torch.cat([pred['loc_propose_pos'][..., :model.output_dim],\n",
    "                                pred['scale_propose_pos'][..., :model.output_dim]], dim=-1)\n",
    "        traj_refine = torch.cat([pred['loc_refine_pos'][..., :model.output_dim],\n",
    "                                pred['scale_refine_pos'][..., :model.output_dim]], dim=-1)\n",
    "        final_traj_propose=torch.zeros_like(traj_propose)\n",
    "        final_traj_refine=torch.zeros_like(traj_refine)\n",
    "        true_traj_propose=torch.zeros_like(traj_propose)\n",
    "        true_traj_refine=torch.zeros_like(traj_refine)\n",
    "        auto_pred=pred\n",
    "\n",
    "        transition_list = [{'states': [],\n",
    "                'actions': [],\n",
    "                'next_states': [],\n",
    "                'rewards': [],\n",
    "                'dones': []} for _ in range(new_data['agent']['num_nodes'])]\n",
    "\n",
    "        for timestep in range(0,model.num_future_steps,offset):\n",
    "            reg_mask = new_data['agent']['predict_mask'][:, model.num_historical_steps:]\n",
    "            cls_mask = new_data['agent']['predict_mask'][:, -1]\n",
    "            # gt = torch.cat([data['agent']['target'][...,timestep:timestep+offset, :model.output_dim], data['agent']['target'][...,timestep:timestep+offset, -1:]], dim=-1)\n",
    "            # l2_norm = (torch.norm(traj_propose[...,:offset, :model.output_dim] -\n",
    "            #                     gt[..., :model.output_dim].unsqueeze(1), p=2, dim=-1) * reg_mask[...,:offset].unsqueeze(1)).sum(dim=-1)\n",
    "            # best_mode = l2_norm.argmin(dim=-1)\n",
    "            best_mode = torch.randint(1,size=(new_data['agent']['num_nodes'],))\n",
    "                \n",
    "            agent_index = torch.nonzero(new_data['agent']['category']==3,as_tuple=False).item()\n",
    "            state = new_data['agent']['position'][agent_index, model.num_historical_steps - offset : model.num_historical_steps, :model.output_dim]\n",
    "            state = torch.cat([state, new_data['agent']['velocity'][agent_index, model.num_historical_steps - offset : model.num_historical_steps, :model.output_dim]], dim = -1)\n",
    "            next_state = new_data['agent']['position'][agent_index, model.num_historical_steps : model.num_historical_steps + offset, :model.output_dim]\n",
    "            next_state = torch.cat([next_state, new_data['agent']['velocity'][agent_index, model.num_historical_steps : model.num_historical_steps + offset, :model.output_dim]], dim = -1)\n",
    "                \n",
    "            action = new_data['agent']['heading'][agent_index, model.num_historical_steps - offset : model.num_historical_steps]\n",
    "            acceleration = (new_data['agent']['velocity'][agent_index, model.num_historical_steps : model.num_historical_steps + offset, :model.output_dim] - new_data['agent']['velocity'][agent_index, model.num_historical_steps - offset: model.num_historical_steps, :model.output_dim])/(0.1*offset)\n",
    "            action = torch.cat([action.unsqueeze(-1), acceleration],dim=-1)\n",
    "            # a = (a-torch.min(a))/(torch.max(a)-torch.min(a))\n",
    "            # a = 2 * a - 1\n",
    "\n",
    "            transition_list[agent_index]['states'].append(state)\n",
    "            transition_list[agent_index]['actions'].append(action)\n",
    "            transition_list[agent_index]['next_states'].append(next_state)\n",
    "\n",
    "            transition_list[agent_index]['dones'].append(False)\n",
    "            reward = reward_function(new_data, agent_index, offset)\n",
    "            transition_list[agent_index]['rewards'].append(reward)\n",
    "                    \n",
    "\n",
    "            new_data, auto_pred, _, _, (true_trans_position_propose, true_trans_position_refine),(traj_propose, traj_refine) = get_auto_pred(\n",
    "                new_data, auto_pred[\"loc_refine_pos\"][torch.arange(traj_propose.size(0)),best_mode], auto_pred[\"loc_refine_head\"][torch.arange(traj_propose.size(0)),best_mode,:,0], offset,anchor=(init_origin,init_theta,init_rot_mat)\n",
    "            )\n",
    "            true_traj_refine[:,:,timestep:timestep+offset,:2]=new_data[\"agent\"][\"position\"][...,model.num_historical_steps - offset : model.num_historical_steps,:2].unsqueeze(1)\n",
    "            pi = auto_pred['pi']\n",
    "\n",
    "\n",
    "        agent_index = torch.nonzero(new_data['agent']['category']==3,as_tuple=False).item()\n",
    "                \n",
    "        agent = PPO(\n",
    "                batch_id=0,\n",
    "                encoder = model.encoder,\n",
    "                decoder = model.decoder,\n",
    "                data = data.clone(),\n",
    "                agent_index = agent_index,\n",
    "                hidden_dim = config['hidden_dim'],\n",
    "                action_dim = model.output_dim+1,\n",
    "                state_dim = model.output_dim*2,\n",
    "                actor_learning_rate = config['actor_learning_rate'],\n",
    "                critic_learning_rate = config['critic_learning_rate'],\n",
    "                lamda = config['lamda'],\n",
    "                eps = config['eps'],\n",
    "                gamma = config['gamma'],\n",
    "                device = model.device,\n",
    "                agent_num = data['agent']['num_nodes'],\n",
    "                offset = offset,\n",
    "                entropy_coef=config['entropy_coef'],\n",
    "                epochs = config['epochs']\n",
    "        )\n",
    "                \n",
    "        agent.update(transition_list,agent_index)\n",
    "\n",
    "        _return = 0\n",
    "        for t in reversed(range(0, int(model.num_future_steps/offset))):\n",
    "            _return = (config['gamma'] * _return) + float(transition_list[agent_index]['rewards'][t])\n",
    "        cumulative_reward[agent_index]['return'].append(_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_traj_refine[-1][0]\n",
    "window_size = 5\n",
    "moving_avg_rewards = [[] for _ in range(data['agent']['num_nodes'])]\n",
    "\n",
    "\n",
    "for j in range(len(cumulative_reward[agent_index]['return'])-window_size+1):\n",
    "    window = cumulative_reward[agent_index]['return'][j:j+window_size]\n",
    "    avg_reward = np.mean(window)\n",
    "    moving_avg_rewards[agent_index].append(avg_reward)\n",
    "      \n",
    "\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange', 'pink', 'brown', 'gray', 'olive', 'yellow']\n",
    "plt.figure(figsize=(10, 10))\n",
    "x = range(episodes-window_size+1)\n",
    "\n",
    "plt.plot(x, moving_avg_rewards[agent_index], color=colors[0], label=f'focal_agent',linewidth = 3)\n",
    "\n",
    "plt.title('IPPO Rewards')\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.legend()\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(data['agent']['num_nodes']):\n",
    "#     plt.plot(range(num_episodes), loss_list[i], color=colors[i])\n",
    "# plt.savefig(f'/home/guanren/MA-generative-model/figures/loss/loss_{time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())}.png')\n",
    "# plt.close()\n",
    "\n",
    "traj_propose=final_traj_propose\n",
    "traj_refine=final_traj_refine\n",
    "reg_mask = data['agent']['predict_mask'][:, model.num_historical_steps:]\n",
    "cls_mask = data['agent']['predict_mask'][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(50.0)\n",
    "for i in range(6):\n",
    "    xy = true_traj_refine[[data[\"agent\"][\"category\"] == 2]][0].cpu().detach()\n",
    "    plt.plot(xy[i, ..., 0], xy[i, ..., 1])\n",
    "# for i in range(6):\n",
    "#     xy = new_position[1][data[\"agent\"][\"category\"] == 3][0].cpu().detach()\n",
    "#     plt.plot(xy[i, ..., 0], xy[i, ..., 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.value for x in _STATIC_OBJECT_TYPES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "data['agent']['position'][data['agent']['category']==3][0,45]\n",
    "print(data['agent']['category']==3)\n",
    "print(torch.nonzero(data['agent']['category']==3,as_tuple=False).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "with open(\"configs/PPO.yaml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "file.close()\n",
    "\n",
    "with torch.no_grad():\n",
    "        offset=5\n",
    "        new_data=new_input_data.cuda().clone()\n",
    "        pred = model(new_data)\n",
    "        traj_propose = torch.cat([pred['loc_propose_pos'][..., :model.output_dim],\n",
    "                                pred['scale_propose_pos'][..., :model.output_dim]], dim=-1)\n",
    "        traj_refine = torch.cat([pred['loc_refine_pos'][..., :model.output_dim],\n",
    "                                pred['scale_refine_pos'][..., :model.output_dim]], dim=-1)\n",
    "        auto_pred=pred\n",
    "\n",
    "        for i in range(30,110):\n",
    "          if i<50:\n",
    "              plot_traj_with_data(new_data,bounds=30,t=i)\n",
    "          else:\n",
    "              if i%offset==0:\n",
    "                  # true_trans_position_propose=new_true_trans_position_propose\n",
    "                  true_trans_position_refine=new_true_trans_position_refine\n",
    "                  # reg_mask = new_data['agent']['predict_mask'][:, model.num_historical_steps:]\n",
    "                  # cls_mask = new_data['agent']['predict_mask'][:, -1]\n",
    "                  # gt = torch.cat([data['agent']['target'][...,timestep:timestep+offset, :model.output_dim], data['agent']['target'][...,timestep:timestep+offset, -1:]], dim=-1)\n",
    "                  # l2_norm = (torch.norm(traj_propose[:-1,...,:offset, :model.output_dim] -\n",
    "                  #                     gt[..., :model.output_dim].unsqueeze(1), p=2, dim=-1) * reg_mask[:-1,...,:offset].unsqueeze(1)).sum(dim=-1)\n",
    "                  # best_mode = l2_norm.argmin(dim=-1)\n",
    "                  best_mode=torch.randint(1,size=(new_input_data['agent']['num_nodes'],))\n",
    "\n",
    "                  transition_list = [{'states': [],\n",
    "                    'actions': [],\n",
    "                    'next_states': [],\n",
    "                    'rewards': [],\n",
    "                    'dones': []} for _ in range(new_data['agent']['num_nodes'])]\n",
    "                \n",
    "                  agent_index = torch.nonzero(new_data['agent']['category']==3,as_tuple=False).item()\n",
    "                  state = new_data['agent']['position'][agent_index, model.num_historical_steps - offset : model.num_historical_steps, :model.output_dim]\n",
    "                  state = torch.cat([state, new_data['agent']['velocity'][agent_index, model.num_historical_steps - offset : model.num_historical_steps, :model.output_dim]], dim = -1)\n",
    "                  next_state = new_data['agent']['position'][agent_index, model.num_historical_steps : model.num_historical_steps + offset, :model.output_dim]\n",
    "                  next_state = torch.cat([next_state, new_data['agent']['velocity'][agent_index, model.num_historical_steps : model.num_historical_steps + offset, :model.output_dim]], dim = -1)\n",
    "                      \n",
    "                  action = new_data['agent']['heading'][agent_index, model.num_historical_steps - offset : model.num_historical_steps]\n",
    "                  acceleration = (new_data['agent']['velocity'][agent_index, model.num_historical_steps : model.num_historical_steps + offset, :model.output_dim] - new_data['agent']['velocity'][agent_index, model.num_historical_steps - offset: model.num_historical_steps, :model.output_dim])/(0.1*offset)\n",
    "                  action = torch.cat([action.unsqueeze(-1), acceleration],dim=-1)\n",
    "                  # a = (a-torch.min(a))/(torch.max(a)-torch.min(a))\n",
    "                  # a = 2 * a - 1\n",
    "\n",
    "                  transition_list[agent_index]['states'].append(state)\n",
    "                  transition_list[agent_index]['actions'].append(action)\n",
    "                  transition_list[agent_index]['next_states'].append(next_state)\n",
    "\n",
    "                  transition_list[agent_index]['dones'].append(False)\n",
    "                  reward = reward_function(new_data, agent_index, offset)\n",
    "                  transition_list[agent_index]['rewards'].append(reward)\n",
    "                          \n",
    "\n",
    "                  new_data, auto_pred, _, _, (true_trans_position_propose, true_trans_position_refine),(traj_propose, traj_refine) = get_auto_pred(\n",
    "                      new_data, auto_pred[\"loc_refine_pos\"][torch.arange(traj_propose.size(0)),best_mode], auto_pred[\"loc_refine_head\"][torch.arange(traj_propose.size(0)),best_mode,:,0], offset,anchor=(init_origin,init_theta,init_rot_mat)\n",
    "                  )\n",
    "                  true_traj_refine[:,:,timestep:timestep+offset,:2]=new_data[\"agent\"][\"position\"][...,model.num_historical_steps - offset : model.num_historical_steps,:2].unsqueeze(1)\n",
    "                  pi = auto_pred['pi']\n",
    "\n",
    "\n",
    "                  agent_index = torch.nonzero(new_data['agent']['category']==3,as_tuple=False).item()\n",
    "                          \n",
    "                  agent = PPO(\n",
    "                          batch_id=0,\n",
    "                          encoder = model.encoder,\n",
    "                          decoder = model.decoder,\n",
    "                          data = data.clone(),\n",
    "                          agent_index = agent_index,\n",
    "                          hidden_dim = config['hidden_dim'],\n",
    "                          action_dim = model.output_dim+1,\n",
    "                          state_dim = model.output_dim*2,\n",
    "                          actor_learning_rate = config['actor_learning_rate'],\n",
    "                          critic_learning_rate = config['critic_learning_rate'],\n",
    "                          lamda = config['lamda'],\n",
    "                          eps = config['eps'],\n",
    "                          gamma = config['gamma'],\n",
    "                          device = model.device,\n",
    "                          agent_num = data['agent']['num_nodes'],\n",
    "                          offset = offset,\n",
    "                          entropy_coef=config['entropy_coef'],\n",
    "                          epochs = config['epochs']\n",
    "                  )\n",
    "                          \n",
    "                  agent.update(transition_list,agent_index)\n",
    "\n",
    "                  plot_traj_with_data(new_data,bounds=30,t=50-offset)\n",
    "              else:\n",
    "                  plot_traj_with_data(new_data,bounds=30,t=50-offset+i%offset)\n",
    "              for j in range(6):\n",
    "                  xy = true_trans_position_refine[new_data[\"agent\"][\"category\"] == 3][0].cpu()\n",
    "                  plt.plot(xy[j, ..., 0], xy[j, ..., 1])\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        frame = img.open(buf)\n",
    "        frames.append(frame)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "vid_path = \"test_ppo.mp4\"\n",
    "video = cv2.VideoWriter(vid_path, fourcc, fps=10, frameSize=frames[0].size)\n",
    "for i in range(len(frames)):\n",
    "    frame_temp = frames[i].copy()\n",
    "    video.write(cv2.cvtColor(np.array(frame_temp), cv2.COLOR_RGB2BGR))\n",
    "video.release()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
